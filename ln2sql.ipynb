{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, re\n",
    "import unicodedata\n",
    "import imp\n",
    "imp.reload(sys)\n",
    "#sys.setdefaultencoding(\"utf-8\")\n",
    "\n",
    "class LangConfig:\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tself.avg_keywords = []\n",
    "\t\tself.sum_keywords = []\n",
    "\t\tself.max_keywords = []\n",
    "\t\tself.min_keywords = []\n",
    "\t\tself.count_keywords = []\n",
    "\t\tself.junction_keywords = []\n",
    "\t\tself.disjunction_keywords = []\n",
    "\t\tself.greater_keywords = []\n",
    "\t\tself.less_keywords = []\n",
    "\t\tself.between_keywords = []\n",
    "\t\tself.order_by_keywords = []\n",
    "\t\tself.group_by_keywords = []\n",
    "\t\tself.negation_keywords = []\n",
    "\n",
    "\tdef get_avg_keywords(self):\n",
    "\t\treturn self.avg_keywords\n",
    "\n",
    "\tdef get_sum_keywords(self):\n",
    "\t\treturn self.sum_keywords\n",
    "\n",
    "\tdef get_max_keywords(self):\n",
    "\t\treturn self.max_keywords\n",
    "\n",
    "\tdef get_min_keywords(self):\n",
    "\t\treturn self.min_keywords\n",
    "\n",
    "\tdef get_count_keywords(self):\n",
    "\t\treturn self.count_keywords\n",
    "\n",
    "\tdef get_junction_keywords(self):\n",
    "\t\treturn self.junction_keywords\n",
    "\n",
    "\tdef get_disjunction_keywords(self):\n",
    "\t\treturn self.disjunction_keywords\n",
    "\n",
    "\tdef get_greater_keywords(self):\n",
    "\t\treturn self.greater_keywords\n",
    "\n",
    "\tdef get_less_keywords(self):\n",
    "\t\treturn self.less_keywords\n",
    "\n",
    "\tdef get_between_keywords(self):\n",
    "\t\treturn self.between_keywords\n",
    "\n",
    "\tdef get_order_by_keywords(self):\n",
    "\t\treturn self.order_by_keywords\n",
    "\n",
    "\tdef get_group_by_keywords(self):\n",
    "\t\treturn self.group_by_keywords\n",
    "\n",
    "\tdef get_negation_keywords(self):\n",
    "\t\treturn self.negation_keywords\n",
    "\n",
    "\tdef remove_accents(self, string):\n",
    "\t\tnkfd_form = unicodedata.normalize('NFKD', str(string))\n",
    "\t\treturn u\"\".join([c for c in nkfd_form if not unicodedata.combining(c)])\n",
    "\n",
    "\tdef load(self, path):\n",
    "\t\twith open(path) as f:\n",
    "\t\t\tcontent = f.readlines()\n",
    "\t\t\tself.avg_keywords = list(map(self.remove_accents, list(map(str.strip, content[0].replace(':',',').split(\",\")))))\n",
    "\t\t\tself.avg_keywords = self.avg_keywords[1:len(list(self.avg_keywords))]\n",
    "\t\t\tself.sum_keywords = list(map(self.remove_accents, list(map(str.strip, content[1].replace(':',',').split(\",\")))))\n",
    "\t\t\tself.sum_keywords = self.sum_keywords[1:len(list(self.sum_keywords))]\n",
    "\t\t\tself.max_keywords =list(map(self.remove_accents, list(map(str.strip, content[2].replace(':',',').split(\",\")))))\n",
    "\t\t\tself.max_keywords = self.max_keywords[1:len(list(self.max_keywords))]\n",
    "\t\t\tself.min_keywords = list(map(self.remove_accents, list(map(str.strip, content[3].replace(':',',').split(\",\")))))\n",
    "\t\t\tself.min_keywords = self.min_keywords[1:len(list(self.min_keywords))]\n",
    "\t\t\tself.count_keywords = list(map(self.remove_accents, list(map(str.strip, content[4].replace(':',',').split(\",\")))))\n",
    "\t\t\tself.count_keywords = self.count_keywords[1:len(list(self.count_keywords))]\n",
    "\t\t\tself.junction_keywords = list(map(self.remove_accents,list(map(str.strip, content[5].replace(':',',').split(\",\")))))\n",
    "\t\t\tself.junction_keywords = self.junction_keywords[1:len(list(self.junction_keywords))]\n",
    "\t\t\tself.disjunction_keywords = list(map(self.remove_accents, list(map(str.strip, content[6].replace(':',',').split(\",\")))))\n",
    "\t\t\tself.disjunction_keywords = self.disjunction_keywords[1:len(list(self.disjunction_keywords))]\n",
    "\t\t\tself.greater_keywords = list(map(self.remove_accents, list(map(str.strip, content[7].replace(':',',').split(\",\")))))\n",
    "\t\t\tself.greater_keywords = self.greater_keywords[1:len(list(self.greater_keywords))]\n",
    "\t\t\tself.less_keywords = list(map(self.remove_accents, list(map(str.strip, content[8].replace(':',',').split(\",\")))))\n",
    "\t\t\tself.less_keywords = self.less_keywords[1:len(list(self.less_keywords))]\n",
    "\t\t\tself.between_keywords = list(map(self.remove_accents, list(map(str.strip, content[9].replace(':',',').split(\",\")))))\n",
    "\t\t\tself.between_keywords = self.between_keywords[1:len(list(self.between_keywords))]\n",
    "\t\t\tself.order_by_keywords = list(map(self.remove_accents,list( map(str.strip, content[10].replace(':',',').split(\",\")))))\n",
    "\t\t\tself.order_by_keywords = self.order_by_keywords[1:len(list(self.order_by_keywords))]\n",
    "\t\t\tself.group_by_keywords = list(map(self.remove_accents, list(map(str.strip, content[11].replace(':',',').split(\",\")))))\n",
    "\t\t\tself.group_by_keywords = self.group_by_keywords[1:len(list(self.group_by_keywords))]\n",
    "\t\t\tself.negation_keywords = list(map(self.remove_accents, list(map(str.strip, content[12].replace(':',',').split(\",\")))))\n",
    "\t\t\tself.negation_keywords = self.negation_keywords[1:len(list(self.negation_keywords))]\n",
    "\n",
    "\tdef print_me(self):\n",
    "\t\tif settings.DEBUG :\n",
    "\t\t\tprint (self.avg_keywords)\n",
    "\t\t\tprint (self.sum_keywords)\n",
    "\t\t\tprint (self.max_keywords)\n",
    "\t\t\tprint (self.min_keywords)\n",
    "\t\t\tprint (self.count_keywords)\n",
    "\t\t\tprint (self.junction_keywords)\n",
    "\t\t\tprint (self.disjunction_keywords)\n",
    "\t\t\tprint (self.greater_keywords)\n",
    "\t\t\tprint (self.less_keywords)\n",
    "\t\t\tprint (self.between_keywords)\n",
    "\t\t\tprint (self.order_by_keywords)\n",
    "\t\t\tprint (self.group_by_keywords)\n",
    "\t\t\tprint (self.negation_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "\n",
    "import sys\n",
    "import unicodedata\n",
    "\n",
    "imp.reload(sys)\n",
    "#sys.setdefaultencoding(\"utf-8\")\n",
    "\n",
    "class Column:\n",
    "    name = ''\n",
    "    type = ''\n",
    "    is_primary = False\n",
    "    \n",
    "    def __init__(self, name=None, type=None, is_primary=None):\n",
    "        if name is None:\n",
    "            self.name = ''\n",
    "        else:\n",
    "            self.name = name\n",
    "        if type is None:\n",
    "            self.type = ''\n",
    "        else:\n",
    "            self.type = type\n",
    "        if is_primary is None:\n",
    "            self.is_primary = False\n",
    "        else:\n",
    "            self.is_primary = is_primary\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    \n",
    "    def set_name(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def get_type(self):\n",
    "        return self.type\n",
    "    \n",
    "    def set_type(self, type):\n",
    "        self.type = type\n",
    "\n",
    "    def is_primary(self):\n",
    "        return self.is_primary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "\n",
    "import sys\n",
    "import unicodedata\n",
    "\n",
    "class settings:\n",
    "    DEBUG=False\n",
    "\n",
    "imp.reload(sys)\n",
    "#sys.setdefaultencoding(\"utf-8\")\n",
    "\n",
    "#from Column import Column\n",
    "\n",
    "class Table:\n",
    "    name = ''\n",
    "    columns = []\n",
    "    primary_keys = []\n",
    "    foreign_keys = []\n",
    "    \n",
    "    def __init__(self, name=None, columns=None, primary_keys=None):\n",
    "\n",
    "        if name is None:\n",
    "            self.name = ''\n",
    "        else:\n",
    "            self.name = name\n",
    "        \n",
    "        if columns is None:\n",
    "            self.columns = []\n",
    "        else:\n",
    "            self.columns = columns\n",
    "        \n",
    "        if primary_keys is None:\n",
    "            self.primary_keys = []\n",
    "        else:\n",
    "            self.primary_keys = primary_keys\n",
    "    \n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    \n",
    "    def set_name(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def get_number_of_columns(self):\n",
    "        return len(self.columns)\n",
    "    \n",
    "    def get_columns(self):\n",
    "        return self.columns\n",
    "\n",
    "    def add_column(self, column_name, column_type):\n",
    "        self.columns.append(Column(column_name, column_type))\n",
    "\n",
    "    def get_number_of_primary_keys(self):\n",
    "        return len(self.primary_keys)\n",
    "\n",
    "    def get_primary_keys(self):\n",
    "        return self.primary_keys\n",
    "\n",
    "    def add_primary_key(self, primary_key):\n",
    "        if settings.DEBUG:\n",
    "            print ('%s : primary key added:%s' % (self.name, primary_key))\n",
    "        self.primary_keys.append(primary_key)\n",
    "\n",
    "    def get_number_of_foreign_keys(self):\n",
    "        return len(self.foreign_keys)\n",
    "\n",
    "    def get_foreign_keys(self):\n",
    "        return self.foreign_keys\n",
    "\n",
    "    def add_foreign_key(self, col, ref_table, ref_col):\n",
    "        if settings.DEBUG:\n",
    "            print ('foreign key added : %s.%s->%s.%s' % (self.name, col, ref_table, ref_col))\n",
    "        self.foreign_keys.append({'col':col,'ref_table':ref_table,'ref_col':ref_col})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "\n",
    "import sys\n",
    "import unicodedata\n",
    "\n",
    "imp.reload(sys)\n",
    "#sys.setdefaultencoding(\"utf-8\")\n",
    "\n",
    "class StopwordFilter:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.list = []\n",
    "    \n",
    "    def add_stopword(self, word):\n",
    "        self.list.append(word)\n",
    "\n",
    "    def get_stopword_list(self):\n",
    "        return self.list\n",
    "    \n",
    "    def filter(self, sentence):\n",
    "        tmp_sentence = []\n",
    "        for word in sentence:\n",
    "            word = self.remove_accents(word).lower()\n",
    "            if word not in self.list:\n",
    "                tmp_sentence.append(word)\n",
    "        return tmp_sentence\n",
    "\n",
    "    def remove_accents(self, string):\n",
    "        nkfd_form = unicodedata.normalize('NFKD', str(string))\n",
    "        return u\"\".join([c for c in nkfd_form if not unicodedata.combining(c)])\n",
    "\n",
    "    def load(self, lang):\n",
    "        with open('./stopwords/' + lang + '.txt') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            for word in lines:\n",
    "                stopword = self.remove_accents(word).lower()\n",
    "                self.list.append(stopword)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "\n",
    "import sys\n",
    "imp.reload(sys)\n",
    "#sys.setdefaultencoding(\"utf-8\")\n",
    "import unicodedata\n",
    "\n",
    "class Thesaurus:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dictionnary = {}\n",
    "    \n",
    "    def add_entry(self, word, synonyms):\n",
    "        self.dictionnary[word] = synonyms\n",
    "    \n",
    "    def add_synonym_of_a_word(self, word, synonym):\n",
    "        self.dictionnary[word].append(synonym)\n",
    "    \n",
    "    def get_synonyms_of_a_word(self, word):\n",
    "        if word in self.dictionnary.keys():\n",
    "            return self.dictionnary[word]\n",
    "\n",
    "    def remove_accents(self, string):\n",
    "        nkfd_form = unicodedata.normalize('NFKD', str(string))\n",
    "        return u\"\".join([c for c in nkfd_form if not unicodedata.combining(c)])\n",
    "\n",
    "    def load(self, path):\n",
    "        with open(path) as f:\n",
    "            content = f.readlines()\n",
    "            # we jump content[0] because it is the encoding-type line : useless to parse\n",
    "            for line_id in range(1,len(content)):\n",
    "                if '(' not in content[line_id]:\n",
    "                    line = content[line_id].split(\"|\")\n",
    "                    word = self.remove_accents(line[0])\n",
    "                    synonyms = self.remove_accents(content[line_id + 1]).split(\"|\")\n",
    "                    synonyms.pop(0)\n",
    "                    self.add_entry(word, synonyms)\n",
    "\n",
    "    def print_me(self):\n",
    "        for keys,values in self.dictionnary.items():\n",
    "            print(keys)\n",
    "            print(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "#from Table import Table\n",
    "#import settings\n",
    "\n",
    "imp.reload(sys)\n",
    "#sys.setdefaultencoding(\"utf-8\")\n",
    "\n",
    "\n",
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'\n",
    "\n",
    "\n",
    "class Database:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.tables = []\n",
    "\n",
    "    def get_number_of_tables(self):\n",
    "        return len(self.tables)\n",
    "\n",
    "    def get_tables(self):\n",
    "        return self.tables\n",
    "\n",
    "    def get_tables_into_dictionnary(self):\n",
    "        data = {}\n",
    "        for table in self.tables:\n",
    "            data[table.name] = []\n",
    "            for column in table.columns:\n",
    "                data[table.name].append(column.name)\n",
    "        return data\n",
    "\n",
    "    def get_primary_keys_by_table(self):\n",
    "        data = {}\n",
    "        for table in self.tables:\n",
    "            data[table.name] = table.primary_keys\n",
    "        return data\n",
    "\n",
    "    def get_primary_keys_of_table(self, table):\n",
    "        for _table in self.tables:\n",
    "            if _table.name == table:\n",
    "                return _table.primary_keys\n",
    "\n",
    "    def get_foreign_keys_of_table(self, table):\n",
    "        for _table in self.tables:\n",
    "            if _table.name == table:\n",
    "                return _table.get_foreign_keys()\n",
    "\n",
    "    def add_table(self, table):\n",
    "        self.tables.append(table)\n",
    "\n",
    "    def load(self, path):\n",
    "        with open(path) as f:\n",
    "            content = f.read()\n",
    "\n",
    "            tables_string = [p.split(';')[0]\n",
    "                             for p in content.split('CREATE') if ';' in p]\n",
    "            for table_string in tables_string:\n",
    "                if 'TABLE' in table_string:\n",
    "                    table = self.create_table(table_string)\n",
    "                    self.add_table(table)\n",
    "\n",
    "            alter_table_string = [p.split(';')[0]\n",
    "                                  for p in content.split('ALTER') if ';' in p]\n",
    "            for s in alter_table_string:\n",
    "                if 'TABLE' in s:\n",
    "                    self.alter_table(s)\n",
    "\n",
    "    def predict_type(self, string):\n",
    "        if 'int' in string.lower():\n",
    "            return 'int'\n",
    "        elif 'char' in string.lower() or 'text' in string.lower():\n",
    "            return 'string'\n",
    "        elif 'date' in string.lower():\n",
    "            return 'date'\n",
    "        else:\n",
    "            return 'unknow'\n",
    "\n",
    "    def create_table(self, table_string):\n",
    "        lines = table_string.split(\"\\n\")\n",
    "        table = Table()\n",
    "        for line in lines:\n",
    "            if 'TABLE' in line:\n",
    "                table_name = re.search(\"`(\\w+)`\", line)\n",
    "                table.set_name(table_name.group(1))\n",
    "            elif 'PRIMARY KEY' in line:\n",
    "                primary_key_columns = re.findall(\"`(\\w+)`\", line)\n",
    "                for primary_key_column in primary_key_columns:\n",
    "                    table.add_primary_key(primary_key_column)\n",
    "            else:\n",
    "                column_name = re.search(\"`(\\w+)`\", line)\n",
    "                if column_name is not None:\n",
    "                    column_type = self.predict_type(line)\n",
    "                    table.add_column(column_name.group(1), column_type)\n",
    "        return table\n",
    "\n",
    "    def alter_table(self, alter_string):\n",
    "        lines = alter_string.replace('\\n', ' ').split(';')\n",
    "        for line in lines:\n",
    "            if 'PRIMARY KEY' in line:\n",
    "                table_name = re.search(\"TABLE `(\\w+)`\", line).group(1)\n",
    "                table = [t for t in self.tables if t.get_name() == table_name][\n",
    "                    0]\n",
    "\n",
    "                primary_key_columns = re.findall(\n",
    "                    \"PRIMARY KEY \\(`(\\w+)`\\)\", line)\n",
    "                for primary_key_column in primary_key_columns:\n",
    "                    table.add_primary_key(primary_key_column)\n",
    "            elif 'FOREIGN KEY' in line:\n",
    "                table_name = re.search(\"TABLE `(\\w+)`\", line).group(1)\n",
    "                table = [t for t in self.tables if t.get_name() == table_name][\n",
    "                    0]\n",
    "\n",
    "                foreign_keys_list = re.findall(\n",
    "                    \"FOREIGN KEY \\(`(\\w+)`\\) REFERENCES `(\\w+)` \\(`(\\w+)`\\)\", line)\n",
    "\n",
    "                for col, ref_table, ref_col in foreign_keys_list:\n",
    "                    table.add_foreign_key(col, ref_table, ref_col)\n",
    "\n",
    "    def print_me(self):\n",
    "        if settings.DEBUG:\n",
    "            for table in self.tables:\n",
    "                print('+-------------------------------------+')\n",
    "                print(\"| %25s           |\" % (table.name.upper()))\n",
    "                print('+-------------------------------------+')\n",
    "                for column in table.columns:\n",
    "                    if column.name in table.primary_keys:\n",
    "                        print(\"| ðŸ”‘ %31s           |\" % (\n",
    "                            color.BOLD + column.name + ' (' + column.type + ')' + color.END))\n",
    "                    else:\n",
    "                        print(\"|   %23s           |\" %\n",
    "                              (column.name + ' (' + column.type + ')'))\n",
    "                print('+-------------------------------------+\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "\n",
    "import sys\n",
    "import unicodedata\n",
    "\n",
    "#imp.reload(simp.ys)\n",
    "#sys.setdefaultencoding(\"utf-8\")\n",
    "\n",
    "class color:\n",
    "    # PURPLE = '\\033[95m'\n",
    "    # CYAN = '\\033[96m'\n",
    "    # DARKCYAN = '\\033[36m'\n",
    "    # BLUE = '\\033[94m'\n",
    "    # GREEN = '\\033[92m'\n",
    "    # YELLOW = '\\033[93m'\n",
    "    # RED = '\\033[91m'\n",
    "    # BOLD = '\\033[1m'\n",
    "    # UNDERLINE = '\\033[4m'\n",
    "    # END = '\\033[0m'\n",
    "\n",
    "    PURPLE = ''\n",
    "    CYAN = ''\n",
    "    DARKCYAN = ''\n",
    "    BLUE = ''\n",
    "    GREEN = ''\n",
    "    YELLOW = ''\n",
    "    RED = ''\n",
    "    BOLD = ''\n",
    "    UNDERLINE = ''\n",
    "    END = ''\n",
    "\n",
    "class Select():\n",
    "\tcolumns = []\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tself.columns = []\n",
    "\n",
    "\tdef add_column(self, column, column_type):\n",
    "\t\tif [column, column_type] not in self.columns:\n",
    "\t\t\tself.columns.append([column, column_type])\n",
    "\n",
    "\tdef get_columns(self):\n",
    "\t\treturn self.columns\n",
    "\n",
    "\tdef get_just_column_name(self, column):\n",
    "\t\tif column != str(None):\n",
    "\t\t\treturn column.rsplit('.', 1)[1]\n",
    "\t\telse:\n",
    "\t\t\treturn column\n",
    "\n",
    "\tdef print_column(self, selection):\n",
    "\t\tcolumn = selection[0]\n",
    "\t\tcolumn_type = selection[1]\n",
    "\n",
    "\t\tif column is None:\n",
    "\t\t\tif column_type == 'COUNT':\n",
    "\t\t\t\treturn color.BOLD + 'COUNT(' + color.END + '*' + color.BOLD + ')' + color.END\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn '*'\n",
    "\t\telse:\n",
    "\t\t\tif column_type == 'COUNT':\n",
    "\t\t\t\treturn color.BOLD + 'COUNT(' + color.END + str(column) + color.BOLD + ')' + color.END\n",
    "\t\t\telif column_type == 'AVG':\n",
    "\t\t\t\treturn color.BOLD + 'AVG(' + color.END + str(column) + color.BOLD + ')' + color.END\n",
    "\t\t\telif column_type == 'SUM':\n",
    "\t\t\t\treturn color.BOLD + 'SUM(' + color.END + str(column) + color.BOLD + ')' + color.END\n",
    "\t\t\telif column_type == 'MAX':\n",
    "\t\t\t\treturn color.BOLD + 'MAX(' + color.END + str(column) + color.BOLD + ')' + color.END\n",
    "\t\t\telif column_type == 'MIN':\n",
    "\t\t\t\treturn color.BOLD + 'MIN(' + color.END + str(column) + color.BOLD + ')' + color.END\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn str(column)\n",
    "\n",
    "\tdef __str__(self):\n",
    "\t\tselect_string = ''\n",
    "\t\tfor i in range(0, len(self.columns)):\n",
    "\t\t\tif i == (len(self.columns)-1):\n",
    "\t\t\t\tselect_string = select_string + str(self.print_column(self.columns[i]))\n",
    "\t\t\telse:\n",
    "\t\t\t\tselect_string = select_string + str(self.print_column(self.columns[i])) + ', '\n",
    "\n",
    "\t\treturn color.BOLD + 'SELECT ' + color.END + select_string\n",
    "\n",
    "\tdef print_json(self, output):\n",
    "\t\tif len(self.columns) >= 1:\n",
    "\t\t\tif len(self.columns) == 1:\n",
    "\t\t\t\toutput.write('\\t\"select\": {\\n')\n",
    "\t\t\t\toutput.write('\\t\\t\"column\": \"' + self.get_just_column_name(str(self.columns[0][0])) + '\",\\n')\n",
    "\t\t\t\toutput.write('\\t\\t\"type\": \"' + str(self.columns[0][1]) + '\"\\n')\n",
    "\t\t\t\toutput.write('\\t},\\n')\n",
    "\t\t\telse:\n",
    "\t\t\t\toutput.write('\\t\"select\": {\\n')\n",
    "\t\t\t\toutput.write('\\t\\t\"columns\": [\\n')\n",
    "\t\t\t\tfor i in range(0, len(self.columns)):\n",
    "\t\t\t\t\tif i == (len(self.columns)-1):\n",
    "\t\t\t\t\t\toutput.write('\\t\\t\\t{ \"column\": \"' + self.get_just_column_name(str(self.columns[i][0])) + '\",\\n')\n",
    "\t\t\t\t\t\toutput.write('\\t\\t\\t  \"type\": \"' + str(self.columns[i][1]) + '\"\\n')\n",
    "\t\t\t\t\t\toutput.write('\\t\\t\\t}\\n')\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\toutput.write('\\t\\t\\t{ \"column\": \"' + self.get_just_column_name(str(self.columns[i][0])) + '\",\\n')\n",
    "\t\t\t\t\t\toutput.write('\\t\\t\\t  \"type\": \"' + str(self.columns[i][1]) + '\"\\n')\n",
    "\t\t\t\t\t\toutput.write('\\t\\t\\t},\\n')\n",
    "\t\t\t\toutput.write('\\t\\t]\\n')\n",
    "\t\t\t\toutput.write('\\t},\\n')\n",
    "\t\telse:\n",
    "\t\t\toutput.write('\\t\"select\": {\\n')\n",
    "\t\t\toutput.write('\\t},\\n')\n",
    "\n",
    "class From():\n",
    "\ttable = ''\n",
    "\n",
    "\tdef __init__(self, table=None):\n",
    "\t\tif table is not None:\n",
    "\t\t\tself.table = table\n",
    "\t\telse:\n",
    "\t\t\tself.table = ''\n",
    "\n",
    "\tdef set_table(self, table):\n",
    "\t\tself.table = table\n",
    "\n",
    "\tdef get_table(self):\n",
    "\t\treturn self.table\n",
    "\n",
    "\tdef __str__(self):\n",
    "\t\treturn ' ' + color.BOLD + 'FROM ' + color.END + str(self.table)\n",
    "\n",
    "\tdef print_json(self, output):\n",
    "\t\tif self.table != '':\n",
    "\t\t\toutput.write('\\t\"from\": {\\n')\n",
    "\t\t\toutput.write('\\t\\t\"table\": \"' + str(self.table) + '\"\\n')\n",
    "\t\t\toutput.write('\\t},\\n')\n",
    "\t\telse:\n",
    "\t\t\toutput.write('\\t\"from\": {\\n')\n",
    "\t\t\toutput.write('\\t},\\n')\n",
    "\n",
    "class Join():\n",
    "\ttables = []\n",
    "\tlinks = []\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tself.tables = []\n",
    "\t\tself.links = []\n",
    "\n",
    "\tdef add_table(self, table):\n",
    "\t\tif table not in self.tables:\n",
    "\t\t\tself.tables.append(table)\n",
    "\n",
    "\tdef set_links(self, links):\n",
    "\t\tself.links = links\n",
    "\n",
    "\tdef get_tables(self):\n",
    "\t\treturn self.tables\n",
    "\n",
    "\tdef get_links(self):\n",
    "\t\treturn self.links\n",
    "\n",
    "\tdef __str__(self):\n",
    "\t\tif len(self.links) >= 1:\n",
    "\t\t\tstring = ''\n",
    "\t\t\tfor i in range(0, len(self.links)):\n",
    "\t\t\t\tstring += ' ' + 'INNER JOIN ' + str(self.links[i][1][0]) + ' ' + 'ON ' + str(self.links[i][0][0]) + '.' + str(self.links[i][0][1]) + ' = ' + str(self.links[i][1][0]) + '.' + str(self.links[i][1][1])\n",
    "\t\t\treturn string\n",
    "\t\telif len(self.tables) >= 1:\n",
    "\t\t\tif len(self.tables) == 1:\n",
    "\t\t\t\treturn ' ' + color.BOLD + 'NATURAL JOIN ' + color.END + self.tables[0]\n",
    "\t\t\telse:\n",
    "\t\t\t\tstring = ' ' + color.BOLD + 'NATURAL JOIN ' + color.END\n",
    "\t\t\t\tfor i in range(0, len(self.tables)):\n",
    "\t\t\t\t\tif i == (len(self.tables)-1):\n",
    "\t\t\t\t\t\tstring += str(self.tables[i])\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tstring += str(self.tables[i]) + ', '\n",
    "\t\t\t\treturn string\n",
    "\t\telse:\n",
    "\t\t\treturn ''\n",
    "\n",
    "\tdef print_json(self, output):\n",
    "\t\tif len(self.tables) >= 1:\n",
    "\t\t\tif len(self.tables) == 1:\n",
    "\t\t\t\toutput.write('\\t\"join\": {\\n')\n",
    "\t\t\t\toutput.write('\\t\\t\"table\": \"' + str(self.tables[0]) + '\"\\n')\n",
    "\t\t\t\toutput.write('\\t},\\n')\n",
    "\t\t\telse:\n",
    "\t\t\t\toutput.write('\\t\"join\": {\\n')\n",
    "\t\t\t\toutput.write('\\t\\t\"tables\": [')\n",
    "\t\t\t\tfor i in range(0, len(self.tables)):\n",
    "\t\t\t\t\tif i == (len(self.tables)-1):\n",
    "\t\t\t\t\t\toutput.write('\"' + str(self.tables[i]) + '\"')\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\toutput.write('\"' + str(self.tables[i]) + '\", ')\n",
    "\t\t\t\toutput.write(']\\n')\n",
    "\t\t\t\toutput.write('\\t},\\n')\n",
    "\t\telse:\n",
    "\t\t\toutput.write('\\t\"join\": {\\n')\n",
    "\t\t\toutput.write('\\t},\\n')\n",
    "\n",
    "class Condition():\n",
    "\tcolumn = ''\n",
    "\tcolumn_type = ''\n",
    "\toperator = ''\n",
    "\tvalue = ''\n",
    "\n",
    "\tdef __init__(self, column, column_type, operator, value):\n",
    "\t\tself.column = column\n",
    "\t\tself.column_type = column_type\n",
    "\t\tself.operator = operator\n",
    "\t\tself.value = value\n",
    "\n",
    "\tdef get_column(self):\n",
    "\t\treturn self.column\n",
    "\n",
    "\tdef get_column_type(self):\n",
    "\t\treturn self.column_type\n",
    "\n",
    "\tdef get_operator(self):\n",
    "\t\treturn self.operator\n",
    "\n",
    "\tdef get_value(self):\n",
    "\t\treturn self.value\n",
    "\n",
    "\tdef get_in_list(self):\n",
    "\t\treturn [self.column, self.column_type, self.operator, self.value]\n",
    "\n",
    "\tdef get_just_column_name(self, column):\n",
    "\t\tif column != str(None):\n",
    "\t\t\treturn column.rsplit('.', 1)[1]\n",
    "\t\telse:\n",
    "\t\t\treturn column\n",
    "\n",
    "\tdef get_column_with_type_operation(self, column, column_type):\n",
    "\t\tif column_type is None:\n",
    "\t\t\treturn self.column\n",
    "\t\telse:\n",
    "\t\t\treturn color.BOLD + str(column_type) + '(' + color.END + self.column + color.BOLD + ')' + color.END\n",
    "\n",
    "\tdef get_pretty_operator(self, operator):\n",
    "\t\tif operator == 'BETWEEN':\n",
    "\t\t\treturn color.BOLD + 'BETWEEN' + color.END + ' OOV ' + color.BOLD + 'AND' + color.END\n",
    "\t\telse:\n",
    "\t\t\treturn color.BOLD + operator + color.END\n",
    "\n",
    "\tdef __str__(self):\n",
    "\t\treturn str(self.get_column_with_type_operation(self.column, self.column_type)) + ' ' + str(self.get_pretty_operator(self.operator)) + ' ' + str(self.value)\n",
    "\n",
    "\tdef print_json(self, output):\n",
    "\t\toutput.write('\\t\\t\\t{ \"column\": \"' + self.get_just_column_name(str(self.column)) + '\",\\n\\t\\t\\t  \"type\": \"' + str(self.column_type) + '\",\\n\\t\\t\\t  \"operator\": \"' + str(self.operator) + '\",\\n\\t\\t\\t  \"value\": \"' + str(self.value) + '\"\\n\\t\\t\\t}')\n",
    "\n",
    "class Where():\n",
    "\tconditions = []\n",
    "\n",
    "\tdef __init__(self, clause=None):\n",
    "\t\tif clause is not None:\n",
    "\t\t\tself.conditions.append([None, clause])\n",
    "\t\telse:\n",
    "\t\t\tself.conditions = []\n",
    "\n",
    "\tdef add_condition(self, junction, clause):\n",
    "\t\tself.conditions.append([junction, clause])\n",
    "\n",
    "\tdef get_conditions(self):\n",
    "\t\treturn self.conditions\n",
    "\n",
    "\tdef __str__(self):\n",
    "\t\tstring = ''\n",
    "\t\tif len(self.conditions) >= 1:\n",
    "\t\t\tfor i in range(0, len(self.conditions)):\n",
    "\t\t\t\tif i == 0:\n",
    "\t\t\t\t\tstring += ' ' + color.BOLD + 'WHERE' + color.END + ' ' + str(self.conditions[i][1])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tstring += ' ' + color.BOLD + str(self.conditions[i][0]) + color.END + ' ' + str(self.conditions[i][1])\n",
    "\t\t\treturn string\n",
    "\t\telse:\n",
    "\t\t\treturn string\n",
    "\n",
    "\tdef print_json(self, output):\n",
    "\t\tif len(self.conditions) >= 1:\n",
    "\t\t\tif len(self.conditions) == 1:\n",
    "\t\t\t\toutput.write('\\t\"where\": {\\n')\n",
    "\t\t\t\toutput.write('\\t\\t\"condition\": [\\n')\n",
    "\t\t\t\tself.conditions[0][1].print_json(output)\n",
    "\t\t\t\toutput.write('\\n')\n",
    "\t\t\t\toutput.write('\\t\\t]\\n')\n",
    "\t\t\t\toutput.write('\\t},\\n')\n",
    "\t\t\telse:\n",
    "\t\t\t\toutput.write('\\t\"where\": {\\n')\n",
    "\t\t\t\toutput.write('\\t\\t\"conditions\": [\\n')\n",
    "\t\t\t\tfor i in range(0, len(self.conditions)):\n",
    "\t\t\t\t\tif i != 0:\n",
    "\t\t\t\t\t\toutput.write('\\t\\t\\t{\\n\\t\\t\\t  \"operator\": \"' + str(self.conditions[i][0]) + '\"\\n\\t\\t\\t},\\n')\n",
    "\t\t\t\t\tself.conditions[i][1].print_json(output)\n",
    "\t\t\t\t\tif i != (len(self.conditions)-1):\n",
    "\t\t\t\t\t\toutput.write(',')\n",
    "\t\t\t\t\toutput.write('\\n')\n",
    "\t\t\t\toutput.write('\\t\\t]\\n')\n",
    "\t\t\t\toutput.write('\\t},\\n')\n",
    "\t\telse:\n",
    "\t\t\toutput.write('\\t\"where\": {\\n')\n",
    "\t\t\toutput.write('\\t},\\n')\n",
    "    \n",
    "class GroupBy():\n",
    "\tcolumn = None\n",
    "\n",
    "\tdef __init__(self, column=None):\n",
    "\t\tif column is not None:\n",
    "\t\t\tself.column = column\n",
    "\t\telse:\n",
    "\t\t\tself.column = None\n",
    "\n",
    "\tdef set_column(self, column):\n",
    "\t\tself.column = column\n",
    "\n",
    "\tdef get_column(self):\n",
    "\t\treturn self.column\n",
    "\n",
    "\tdef get_just_column_name(self, column):\n",
    "\t\tif column != str(None):\n",
    "\t\t\treturn column.rsplit('.', 1)[1]\n",
    "\t\telse:\n",
    "\t\t\treturn column\n",
    "\n",
    "\tdef __str__(self):\n",
    "\t\tif self.column is not None:\n",
    "\t\t\treturn ' ' + color.BOLD + 'GROUP BY ' + color.END + str(self.column)\n",
    "\t\telse:\n",
    "\t\t\treturn ''\n",
    "\n",
    "\tdef print_json(self, output):\n",
    "\t\tif self.column is not None:\n",
    "\t\t\toutput.write('\\t\"group_by\": {\\n')\n",
    "\t\t\toutput.write('\\t\\t\"column\": \"' + self.get_just_column_name(str(self.column)) + '\"\\n')\n",
    "\t\t\toutput.write('\\t},\\n')\n",
    "\t\telse:\n",
    "\t\t\toutput.write('\\t\"group_by\": {\\n')\n",
    "\t\t\toutput.write('\\t},\\n')\n",
    "\n",
    "class OrderBy():\n",
    "\tcolumns = []\n",
    "\torder = None\n",
    "\n",
    "\tdef __init__(self, columns=None, order=None):\n",
    "\t\tif columns is not None:\n",
    "\t\t\tself.columns = columns\n",
    "\t\telse:\n",
    "\t\t\tself.columns = []\n",
    "\n",
    "\t\tif order is not None:\n",
    "\t\t\tself.order = order\n",
    "\t\telse:\n",
    "\t\t\tself.order = None\n",
    "\n",
    "\tdef add_column(self, column):\n",
    "\t\tif column not in self.columns:\n",
    "\t\t\tself.columns.append(column)\n",
    "\n",
    "\tdef get_columns(self):\n",
    "\t\treturn self.columns\n",
    "\n",
    "\tdef set_order(self, order):\n",
    "\t\tself.order = order\n",
    "\n",
    "\tdef get_order(self):\n",
    "\t\treturn self.order\n",
    "\n",
    "\tdef get_just_column_name(self, column):\n",
    "\t\tif column != str(None):\n",
    "\t\t\treturn column.rsplit('.', 1)[1]\n",
    "\t\telse:\n",
    "\t\t\treturn column\n",
    "\n",
    "\tdef __str__(self):\n",
    "\t\tif self.columns != []:\n",
    "\t\t\tstring = color.BOLD + 'ORDER BY ' + color.END\n",
    "\t\t\tfor i in range(0, len(self.columns)):\n",
    "\t\t\t\tif i == (len(self.columns)-1):\n",
    "\t\t\t\t\tstring += self.columns[i]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tstring += self.columns[i] + ', '\n",
    "\t\t\tif self.order == 0:\n",
    "\t\t\t\tstring += color.BOLD + ' ASC' + color.END\n",
    "\t\t\telse:\n",
    "\t\t\t\tstring += color.BOLD + ' ASC' + color.END\n",
    "\t\t\treturn ' ' + string\n",
    "\t\telse:\n",
    "\t\t\treturn ''\n",
    "\n",
    "\tdef print_json(self, output):\n",
    "\t\tif len(self.columns) >= 1:\n",
    "\t\t\tif len(self.columns) == 1:\n",
    "\t\t\t\toutput.write('\\t\"order_by\": {\\n')\n",
    "\t\t\t\toutput.write('\\t\\t\"order\": \"' + str(self.order) + '\",\\n')\n",
    "\t\t\t\toutput.write('\\t\\t\"column\": \"' + self.get_just_column_name(str(self.columns[0])) + '\"\\n')\n",
    "\t\t\t\toutput.write('\\t},\\n')\n",
    "\t\t\telse:\n",
    "\t\t\t\toutput.write('\\t\"order_by\": {\\n')\n",
    "\t\t\t\toutput.write('\\t\\t\"order\": \"' + str(self.order) + '\",\\n')\n",
    "\t\t\t\toutput.write('\\t\\t\"columns\": [')\n",
    "\t\t\t\tfor i in range(0, len(self.columns)):\n",
    "\t\t\t\t\tif i == (len(self.columns)-1):\n",
    "\t\t\t\t\t\toutput.write('\"' + self.get_just_column_name(str(self.columns[i])) + '\"')\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\toutput.write('\"' + self.get_just_column_name(str(self.columns[i])) + '\", ')\n",
    "\t\t\t\toutput.write(']\\n')\n",
    "\t\t\t\toutput.write('\\t},\\n')\n",
    "\t\telse:\n",
    "\t\t\toutput.write('\\t\"order_by\": {\\n')\n",
    "\t\t\toutput.write('\\t}\\n')\n",
    "\n",
    "class Query():\n",
    "\tselect = None\n",
    "\t_from = None\n",
    "\tjoin = None\n",
    "\twhere = None\n",
    "\tgroup_by = None\n",
    "\torder_by = None\n",
    "\n",
    "\tdef __init__(self, select=None, _from=None, join=None, where=None, group_by=None, order_by=None):\n",
    "\t\tif select is not None:\n",
    "\t\t\tself.select = select\n",
    "\t\telse:\n",
    "\t\t\tself.select = None\n",
    "\t\tif _from is not None:\n",
    "\t\t\tself._from = _from\n",
    "\t\telse:\n",
    "\t\t\tself._from = None\n",
    "\t\tif join is not None:\n",
    "\t\t\tself.join = join\n",
    "\t\telse:\n",
    "\t\t\tself.join = None\n",
    "\t\tif where is not None:\n",
    "\t\t\tself.where = where\n",
    "\t\telse:\n",
    "\t\t\tself.where = None\n",
    "\t\tif group_by is not None:\n",
    "\t\t\tself.group_by = group_by\n",
    "\t\telse:\n",
    "\t\t\tself.group_by = None\n",
    "\t\tif order_by is not None:\n",
    "\t\t\tself.order_by = order_by\n",
    "\t\telse:\n",
    "\t\t\tself.order_by = None\n",
    "\n",
    "\tdef set_select(self, select):\n",
    "\t\tself.select = select\n",
    "\n",
    "\tdef get_select(self):\n",
    "\t\treturn self.select\n",
    "\n",
    "\tdef set_from(self, _from):\n",
    "\t\tself._from = _from\n",
    "\n",
    "\tdef get_from(self):\n",
    "\t\treturn self._from\n",
    "\n",
    "\tdef set_join(self, join):\n",
    "\t\tself.join = join\n",
    "\n",
    "\tdef get_join(self):\n",
    "\t\treturn self.join\n",
    "\n",
    "\tdef set_where(self, where):\n",
    "\t\tself.where = where\n",
    "\n",
    "\tdef get_where(self):\n",
    "\t\treturn self.where\n",
    "\n",
    "\tdef set_group_by(self, group_by):\n",
    "\t\tself.group_by = group_by\n",
    "\n",
    "\tdef get_group_by(self):\n",
    "\t\treturn self.group_by\n",
    "\n",
    "\tdef set_order_by(self, order_by):\n",
    "\t\tself.order_by = order_by\n",
    "\n",
    "\tdef get_order_by(self):\n",
    "\t\treturn self.order_by\n",
    "\n",
    "\tdef __str__(self):\n",
    "\t\treturn str(self.select) + str(self._from) + str(self.join) + str(self.where) + str(self.group_by) + str(self.order_by) + ';'\n",
    "\n",
    "\tdef print_json(self, filename=\"output.json\"):\n",
    "\t\toutput = open(filename, 'a')\n",
    "\t\toutput.write('{\\n')\n",
    "\t\tself.select.print_json(output)\n",
    "\t\tself._from.print_json(output)\n",
    "\t\tself.join.print_json(output)\n",
    "\t\tself.where.print_json(output)\n",
    "\t\tself.group_by.print_json(output)\n",
    "\t\tself.order_by.print_json(output)\n",
    "\t\toutput.write('}\\n')\n",
    "\t\toutput.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "\n",
    "import sys\n",
    "import unicodedata\n",
    "\n",
    "imp.reload(sys)\n",
    "#sys.setdefaultencoding(\"utf-8\")\n",
    "\n",
    "class ParsingException(Exception):\n",
    "    reason = ''\n",
    "    \n",
    "    def __init__(self, reason):\n",
    "        self.reason = reason\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Error: ' + self.reason\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "class SelectParser(Thread):\n",
    "    def __init__(self, columns_of_select, tables_of_from, phrase, count_keywords, sum_keywords, average_keywords, max_keywords, min_keywords, database_dico):\n",
    "        Thread.__init__(self)\n",
    "        self.select_objects = []\n",
    "        self.columns_of_select = columns_of_select\n",
    "        self.tables_of_from = tables_of_from\n",
    "        self.phrase = phrase\n",
    "        self.count_keywords = count_keywords\n",
    "        self.sum_keywords = sum_keywords\n",
    "        self.average_keywords = average_keywords\n",
    "        self.max_keywords = max_keywords\n",
    "        self.min_keywords = min_keywords\n",
    "        self.database_dico = database_dico\n",
    "\n",
    "    def get_tables_of_column(self, column):\n",
    "        tmp_table = []\n",
    "        for table in self.database_dico:\n",
    "            if column in self.database_dico[table]:\n",
    "                 tmp_table.append(table)\n",
    "        return tmp_table\n",
    "\n",
    "    def get_column_name_with_alias_table(self, column, table_of_from):\n",
    "        one_table_of_column = self.get_tables_of_column(column)[0]\n",
    "        tables_of_column = self.get_tables_of_column(column)\n",
    "        if table_of_from in tables_of_column:\n",
    "            return str(table_of_from) + '.' + str(column)\n",
    "        else:\n",
    "            return str(one_table_of_column) + '.' + str(column)\n",
    "\n",
    "    def run(self):\n",
    "        for table_of_from in self.tables_of_from:\n",
    "            self.select_object = Select()\n",
    "            is_count = False\n",
    "            number_of_select_column = len(self.columns_of_select)\n",
    "\n",
    "            if number_of_select_column == 0:\n",
    "                for count_keyword in self.count_keywords:\n",
    "                    if count_keyword in self.phrase:\n",
    "                        is_count = True\n",
    "\n",
    "                if is_count:\n",
    "                    self.select_object.add_column(None, 'COUNT')\n",
    "                else:\n",
    "                    self.select_object.add_column(None, None)\n",
    "            else:\n",
    "                select_phrases = []\n",
    "                previous_index = 0\n",
    "                for i in range(0,len(self.phrase)):\n",
    "                    if self.phrase[i] in self.columns_of_select:\n",
    "                        select_phrases.append(self.phrase[previous_index:i+1])\n",
    "                        previous_index = i+1\n",
    "\n",
    "                select_phrases.append(self.phrase[previous_index:])\n",
    "\n",
    "                for i in range(0, len(select_phrases)):\n",
    "                    select_type = None\n",
    "                    phrase = ' '.join(select_phrases[i])\n",
    "\n",
    "                    for keyword in self.average_keywords:\n",
    "                        if keyword in phrase:\n",
    "                            select_type = 'AVG'\n",
    "                    for keyword in self.count_keywords:\n",
    "                        if keyword in phrase:\n",
    "                            select_type = 'COUNT'\n",
    "                    for keyword in self.max_keywords:\n",
    "                        if keyword in phrase:\n",
    "                            select_type = 'MAX'\n",
    "                    for keyword in self.min_keywords:\n",
    "                        if keyword in phrase:\n",
    "                            select_type = 'MIN'\n",
    "                    for keyword in self.sum_keywords:\n",
    "                        if keyword in phrase:\n",
    "                            select_type = 'SUM'\n",
    "\n",
    "                    if (i != len(select_phrases)-1) or (select_type is not None):\n",
    "                        if i >= len(self.columns_of_select):\n",
    "                            column = None\n",
    "                        else:\n",
    "                        \tcolumn = self.get_column_name_with_alias_table(self.columns_of_select[i], table_of_from)\n",
    "                        self.select_object.add_column(column, select_type)\n",
    "\n",
    "            self.select_objects.append(self.select_object)\n",
    "\n",
    "\n",
    "    def join(self):\n",
    "        Thread.join(self)\n",
    "        return self.select_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FromParser(Thread):\n",
    "    def __init__(self, tables_of_from, columns_of_select, columns_of_where, database_object):\n",
    "        Thread.__init__(self)\n",
    "        self.queries = []\n",
    "        self.tables_of_from = tables_of_from\n",
    "        self.columns_of_select = columns_of_select\n",
    "        self.columns_of_where = columns_of_where\n",
    "        \n",
    "        self.database_object = database_object\n",
    "        self.database_dico = self.database_object.get_tables_into_dictionnary()\n",
    "\n",
    "    def get_tables_of_column(self, column):\n",
    "        tmp_table = []\n",
    "        for table in self.database_dico:\n",
    "            if column in self.database_dico[table]:\n",
    "                 tmp_table.append(table)\n",
    "        return tmp_table\n",
    "\n",
    "    def intersect(self, a, b):\n",
    "        return list(set(a) & set(b))\n",
    "\n",
    "    def find_fk(self, a, b):\n",
    "        pass\n",
    "\n",
    "    def difference(self, a, b):\n",
    "        differences = []\n",
    "        for _list in a:\n",
    "            if _list not in b:\n",
    "               differences.append(_list)\n",
    "        return differences\n",
    "\n",
    "    def is_direct_join_is_possible(self, table_src, table_trg):\n",
    "        # pk_table_src = self.database_object.get_primary_keys_of_table(table_src)\n",
    "        # pk_table_trg = self.database_object.get_primary_keys_of_table(table_trg)\n",
    "        # match_pk_table_src_with_table_trg = self.intersect(pk_table_src, self.database_dico[table_trg])\n",
    "        # match_pk_table_trg_with_table_src = self.intersect(pk_table_trg, self.database_dico[table_src])\n",
    "        \n",
    "        # if len(match_pk_table_src_with_table_trg) >=1:\n",
    "        #     return [table_src, match_pk_table_src_with_table_trg[0], table_trg]\n",
    "        # elif len(match_pk_table_trg_with_table_src) >= 1:\n",
    "        #     return [table_src, match_pk_table_trg_with_table_src[0], table_trg]\n",
    "\n",
    "\n",
    "\n",
    "        fk_table_src = self.database_object.get_foreign_keys_of_table(table_src)\n",
    "        fk_table_trg = self.database_object.get_foreign_keys_of_table(table_trg)\n",
    "\n",
    "        for fk_dict in fk_table_src:\n",
    "            if fk_dict['ref_table'] == table_trg:\n",
    "                return [(table_src,fk_dict['col']), (table_trg,fk_dict['ref_col'])]\n",
    "\n",
    "        for fk_dict in fk_table_trg:\n",
    "            if fk_dict['ref_table'] == table_src:\n",
    "                return [(table_trg,fk_dict['col']), (table_src, fk_dict['ref_col'])]\n",
    "\n",
    "    def get_all_direct_linked_tables_of_a_table(self, table_src):\n",
    "        links = []\n",
    "        for table_trg in self.database_dico:\n",
    "            if table_trg != table_src:\n",
    "                link = self.is_direct_join_is_possible(table_src, table_trg)\n",
    "                if link is not None:\n",
    "                    links.append(link)\n",
    "        return links\n",
    "\n",
    "    def is_join(self, historic, table_src, table_trg):\n",
    "        historic = historic\n",
    "        links = self.get_all_direct_linked_tables_of_a_table(table_src)\n",
    "\n",
    "        differences = []\n",
    "        for join in links:\n",
    "            if join[1][0] not in historic:\n",
    "                differences.append(join)\n",
    "        links = differences \n",
    "\n",
    "        for join in links:\n",
    "            if join[1][0] == table_trg:\n",
    "                return [0, join]\n",
    "\n",
    "        path = []\n",
    "        historic.append(table_src)\n",
    "\n",
    "        for join in links:\n",
    "            result = [1, self.is_join(historic, join[1][0], table_trg)]\n",
    "            if result[1] != []:\n",
    "                if result[0] == 0:\n",
    "                    path.append(result[1])\n",
    "                    path.append(join)\n",
    "                else:\n",
    "                    path = result[1]\n",
    "                    path.append(join)\n",
    "        return path\n",
    "\n",
    "    def get_link(self, table_src, table_trg):\n",
    "        path = self.is_join([], table_src, table_trg)\n",
    "        if len(path) > 0:\n",
    "            path.pop(0)\n",
    "            path.reverse()\n",
    "        return path\n",
    "\n",
    "    def unique(self, _list):\n",
    "        return [list(x) for x in set(tuple(x) for x in _list)]\n",
    "\n",
    "    def unique_ordered(self, _list):\n",
    "        frequency = []\n",
    "        for element in _list:\n",
    "            if element not in frequency:\n",
    "                frequency.append(element)\n",
    "        return frequency\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        self.queries = []\n",
    "\n",
    "        for table_of_from in self.tables_of_from:\n",
    "            links = []\n",
    "            query = Query()\n",
    "            query.set_from(From(table_of_from))\n",
    "            join_object = Join()\n",
    "            for column in self.columns_of_select:\n",
    "                if column not in self.database_dico[table_of_from]:\n",
    "                    foreign_table = self.get_tables_of_column(column)[0]\n",
    "                    join_object.add_table(foreign_table)\n",
    "                    link = self.get_link(table_of_from, foreign_table)\n",
    "                    links.extend(link)\n",
    "            for column in self.columns_of_where:\n",
    "                if column not in self.database_dico[table_of_from]:\n",
    "                    foreign_table = self.get_tables_of_column(column)[0]\n",
    "                    join_object.add_table(foreign_table)\n",
    "                    link = self.get_link(table_of_from, foreign_table)\n",
    "                    links.extend(link)\n",
    "\n",
    "            join_object.set_links(self.unique_ordered(links))\n",
    "            query.set_join(join_object)\n",
    "            self.queries.append(query)\n",
    "            if len(join_object.get_tables()) > len(join_object.get_links()):\n",
    "                self.queries = None\n",
    "\n",
    "    def join(self):\n",
    "        Thread.join(self)\n",
    "        return self.queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhereParser(Thread):\n",
    "    def __init__(self, phrases, tables_of_from, count_keywords, sum_keywords, average_keywords, max_keywords, min_keywords, greater_keywords, less_keywords, between_keywords, negation_keywords, junction_keywords, disjunction_keywords, database_dico, columns_of_values_of_where):\n",
    "        Thread.__init__(self)\n",
    "        self.where_objects = []\n",
    "        self.phrases = phrases\n",
    "        self.tables_of_from = tables_of_from\n",
    "        self.count_keywords = count_keywords\n",
    "        self.sum_keywords = sum_keywords\n",
    "        self.average_keywords = average_keywords\n",
    "        self.max_keywords = max_keywords\n",
    "        self.min_keywords = min_keywords\n",
    "        self.greater_keywords = greater_keywords\n",
    "        self.less_keywords = less_keywords\n",
    "        self.between_keywords = between_keywords\n",
    "        self.negation_keywords = negation_keywords\n",
    "        self.junction_keywords = junction_keywords\n",
    "        self.disjunction_keywords = disjunction_keywords\n",
    "        self.database_dico = database_dico\n",
    "        # -----------------------------------------------\n",
    "\n",
    "        self.columns_of_values_of_where = columns_of_values_of_where\n",
    "\n",
    "        # -----------------------------------------------\n",
    "\n",
    "    def get_tables_of_column(self, column):\n",
    "        tmp_table = []\n",
    "        for table in self.database_dico:\n",
    "            if column in self.database_dico[table]:\n",
    "                 tmp_table.append(table)\n",
    "        return tmp_table\n",
    "\n",
    "    def get_column_name_with_alias_table(self,column, table_of_from):\n",
    "        one_table_of_column = self.get_tables_of_column(column)[0]\n",
    "        tables_of_column = self.get_tables_of_column(column)\n",
    "        if table_of_from in tables_of_column:\n",
    "            return str(table_of_from) + '.' + str(column)\n",
    "        else:\n",
    "            return str(one_table_of_column) + '.' + str(column)\n",
    "\n",
    "    def intersect(self, a, b):\n",
    "        return list(set(a) & set(b))\n",
    "\n",
    "    def predict_operation_type(self, previous_column_offset, current_column_offset):\n",
    "        interval_offset = range(previous_column_offset, current_column_offset)\n",
    "        if(len(self.intersect(interval_offset, self.count_keyword_offset)) >= 1):\n",
    "            return 'COUNT'\n",
    "        elif(len(self.intersect(interval_offset, self.sum_keyword_offset)) >= 1):\n",
    "            return 'SUM'\n",
    "        elif(len(self.intersect(interval_offset, self.average_keyword_offset)) >= 1):\n",
    "            return 'AVG'\n",
    "        elif(len(self.intersect(interval_offset, self.max_keyword_offset)) >= 1):\n",
    "            return 'MAX'\n",
    "        elif(len(self.intersect(interval_offset, self.min_keyword_offset)) >= 1):\n",
    "            return 'MIN'\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def predict_operator(self, current_column_offset, next_column_offset):\n",
    "        interval_offset = range(current_column_offset, next_column_offset)\n",
    "        if(len(self.intersect(interval_offset, self.negation_keyword_offset)) >= 1) and (len(self.intersect(interval_offset, self.greater_keyword_offset)) >= 1):\n",
    "            return '<'\n",
    "        elif(len(self.intersect(interval_offset, self.negation_keyword_offset)) >= 1) and (len(self.intersect(interval_offset, self.less_keyword_offset)) >= 1):\n",
    "            return '>'\n",
    "        if(len(self.intersect(interval_offset, self.less_keyword_offset)) >= 1):\n",
    "            return '<'\n",
    "        elif(len(self.intersect(interval_offset, self.greater_keyword_offset)) >= 1):\n",
    "            return '>'\n",
    "        elif(len(self.intersect(interval_offset, self.between_keyword_offset)) >= 1):\n",
    "            return 'BETWEEN'\n",
    "        elif(len(self.intersect(interval_offset, self.negation_keyword_offset)) >= 1):\n",
    "            return '!='\n",
    "        else:\n",
    "            return '='\n",
    "\n",
    "    def predict_junction(self, previous_column_offset, current_column_offset):\n",
    "        interval_offset = range(previous_column_offset, current_column_offset)\n",
    "        junction = 'AND'\n",
    "        if(len(self.intersect(interval_offset, self.disjunction_keyword_offset)) >= 1):\n",
    "            return 'OR'\n",
    "        elif(len(self.intersect(interval_offset, self.junction_keyword_offset)) >= 1):\n",
    "            return 'AND'\n",
    "\n",
    "        first_encountered_junction_offset = -1\n",
    "        first_encountered_disjunction_offset = -1\n",
    "\n",
    "        for offset in self.junction_keyword_offset:\n",
    "            if offset >= current_column_offset:\n",
    "                first_encountered_junction_offset = offset\n",
    "                break\n",
    "\n",
    "        for offset in self.disjunction_keyword_offset:\n",
    "            if offset >= current_column_offset:\n",
    "                first_encountered_disjunction_offset = offset\n",
    "                break\n",
    "\n",
    "        if first_encountered_junction_offset >= first_encountered_disjunction_offset:\n",
    "            return 'AND'\n",
    "        else: \n",
    "            return 'OR'\n",
    "\n",
    "    def run(self):\n",
    "        number_of_where_columns = 0\n",
    "        columns_of_where = []\n",
    "        offset_of = {}\n",
    "        column_offset = []\n",
    "        self.count_keyword_offset = []\n",
    "        self.sum_keyword_offset = []\n",
    "        self.average_keyword_offset = []\n",
    "        self.max_keyword_offset = []\n",
    "        self.min_keyword_offset = []\n",
    "        self.greater_keyword_offset = []\n",
    "        self.less_keyword_offset = []\n",
    "        self.between_keyword_offset = []\n",
    "        self.junction_keyword_offset = []\n",
    "        self.disjunction_keyword_offset = []\n",
    "        self.negation_keyword_offset = []\n",
    "\n",
    "        for phrase in self.phrases:\n",
    "            for i in range(0, len(phrase)):\n",
    "                for table in self.database_dico:\n",
    "                    if phrase[i] in self.database_dico[table]:\n",
    "                        number_of_where_columns += 1\n",
    "                        columns_of_where.append(phrase[i])\n",
    "                        offset_of[phrase[i]] = i\n",
    "                        column_offset.append(i)\n",
    "                        break\n",
    "                if phrase[i] in self.count_keywords: # before the column\n",
    "                    self.count_keyword_offset.append(i)\n",
    "                if phrase[i] in self.sum_keywords: # before the column\n",
    "                    self.sum_keyword_offset.append(i)\n",
    "                if phrase[i] in self.average_keywords: # before the column\n",
    "                    self.average_keyword_offset.append(i)\n",
    "                if phrase[i] in self.max_keywords: # before the column\n",
    "                    self.max_keyword_offset.append(i)\n",
    "                if phrase[i] in self.min_keywords: # before the column\n",
    "                    self.min_keyword_offset.append(i)\n",
    "                if phrase[i] in self.greater_keywords: # after the column\n",
    "                    self.greater_keyword_offset.append(i)\n",
    "                if phrase[i] in self.less_keywords: # after the column\n",
    "                    self.less_keyword_offset.append(i)\n",
    "                if phrase[i] in self.between_keywords: # after the column\n",
    "                    self.between_keyword_offset.append(i)\n",
    "                if phrase[i] in self.junction_keywords: # after the column\n",
    "                    self.junction_keyword_offset.append(i)\n",
    "                if phrase[i] in self.disjunction_keywords: # after the column\n",
    "                    self.disjunction_keyword_offset.append(i)\n",
    "                if phrase[i] in self.negation_keywords: # between the column and the equal, greater or less keyword\n",
    "                    self.negation_keyword_offset.append(i)\n",
    "\n",
    "        for table_of_from in self.tables_of_from:\n",
    "            where_object = Where()\n",
    "            \n",
    "            for i in range(0, len(column_offset)):\n",
    "                current = column_offset[i]\n",
    "                if (i==0):\n",
    "                    previous = 0\n",
    "                else:\n",
    "                    previous = column_offset[i-1]\n",
    "\n",
    "                if i == (len(column_offset) - 1):\n",
    "                    _next = 100 # put max integer in python here ?\n",
    "                else:\n",
    "                    _next = column_offset[i+1]\n",
    "\n",
    "                junction = self.predict_junction(previous, current)\n",
    "                column = self.get_column_name_with_alias_table(columns_of_where[i], table_of_from)\n",
    "                operation_type = self.predict_operation_type(previous, current)\n",
    "                \n",
    "                if len(self.columns_of_values_of_where) >= len(columns_of_where):                   \n",
    "                    value = self.columns_of_values_of_where[i]\n",
    "                else:\n",
    "                    value = 'OOV' # Out Of Vocabulary: feature not implemented yet\n",
    "\n",
    "                # -----------------------------------------------\n",
    "                    \n",
    "                operator = self.predict_operator(current, _next)\n",
    "                where_object.add_condition(junction, Condition(column, operation_type, operator, value))\n",
    "            self.where_objects.append(where_object)\n",
    "\n",
    "    def join(self):\n",
    "        Thread.join(self)\n",
    "        return self.where_objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupByParser(Thread):\n",
    "    def __init__(self, phrases, tables_of_from, database_dico):\n",
    "        Thread.__init__(self)\n",
    "        self.group_by_objects = []\n",
    "        self.phrases = phrases\n",
    "        self.tables_of_from = tables_of_from\n",
    "        self.database_dico = database_dico\n",
    "\n",
    "    def get_tables_of_column(self, column):\n",
    "        tmp_table = []\n",
    "        for table in self.database_dico:\n",
    "            if column in self.database_dico[table]:\n",
    "                 tmp_table.append(table)\n",
    "        return tmp_table\n",
    "\n",
    "    def get_column_name_with_alias_table(self, column, table_of_from):\n",
    "        one_table_of_column = self.get_tables_of_column(column)[0]\n",
    "        tables_of_column = self.get_tables_of_column(column)\n",
    "        if table_of_from in tables_of_column:\n",
    "            return str(table_of_from) + '.' + str(column)\n",
    "        else:\n",
    "            return str(one_table_of_column) + '.' + str(column)\n",
    "\n",
    "    def run(self):\n",
    "        for table_of_from in self.tables_of_from:\n",
    "            group_by_object = GroupBy()\n",
    "            for phrase in self.phrases:\n",
    "                for i in range(0, len(phrase)):\n",
    "                    for table in self.database_dico:\n",
    "                        if phrase[i] in self.database_dico[table]:\n",
    "                            column = self.get_column_name_with_alias_table(phrase[i], table_of_from)\n",
    "                            group_by_object.set_column(column)\n",
    "            self.group_by_objects.append(group_by_object)\n",
    "\n",
    "    def join(self):\n",
    "        Thread.join(self)\n",
    "        return self.group_by_objects\n",
    "\n",
    "class OrderByParser(Thread):\n",
    "    def __init__(self, phrases, tables_of_from, database_dico):\n",
    "        Thread.__init__(self)\n",
    "        self.order_by_objects = []\n",
    "        self.phrases = phrases\n",
    "        self.tables_of_from = tables_of_from\n",
    "        self.database_dico = database_dico\n",
    "\n",
    "    def get_tables_of_column(self, column):\n",
    "        tmp_table = []\n",
    "        for table in self.database_dico:\n",
    "            if column in self.database_dico[table]:\n",
    "                 tmp_table.append(table)\n",
    "        return tmp_table\n",
    "\n",
    "    def get_column_name_with_alias_table(self, column, table_of_from):\n",
    "        one_table_of_column = self.get_tables_of_column(column)[0]\n",
    "        tables_of_column = self.get_tables_of_column(column)\n",
    "        if table_of_from in tables_of_column:\n",
    "            return str(table_of_from) + '.' + str(column)\n",
    "        else:\n",
    "            return str(one_table_of_column) + '.' + str(column)\n",
    "\n",
    "    def run(self):\n",
    "        for table_of_from in self.tables_of_from:\n",
    "            order_by_object = OrderBy()\n",
    "            for phrase in self.phrases:\n",
    "                for i in range(0, len(phrase)):\n",
    "                    for table in self.database_dico:\n",
    "                        if phrase[i] in self.database_dico[table]:\n",
    "                            column = self.get_column_name_with_alias_table(phrase[i], table_of_from)\n",
    "                            order_by_object.add_column(column)\n",
    "            order_by_object.set_order(0)\n",
    "            self.order_by_objects.append(order_by_object)\n",
    "\n",
    "    def join(self):\n",
    "        Thread.join(self)\n",
    "        return self.order_by_objects\n",
    "\n",
    "class Parser:\n",
    "    database_object = None\n",
    "    database_dico = None\n",
    "    language = None\n",
    "    thesaurus_object = None\n",
    "\n",
    "    count_keywords = []\n",
    "    sum_keywords = []\n",
    "    average_keywords = []\n",
    "    max_keywords = []\n",
    "    min_keywords = []\n",
    "    junction_keywords = []\n",
    "    disjunction_keywords = []\n",
    "    greater_keywords = []\n",
    "    less_keywords = []\n",
    "    between_keywords = []\n",
    "    order_by_keywords = []\n",
    "    group_by_keywords = []\n",
    "    negation_keywords = []\n",
    "\n",
    "    def __init__(self, database, config):\n",
    "        self.database_object = database\n",
    "        self.database_dico = self.database_object.get_tables_into_dictionnary()\n",
    "\n",
    "        self.count_keywords = config.get_count_keywords()\n",
    "        self.sum_keywords = config.get_sum_keywords()\n",
    "        self.average_keywords = config.get_avg_keywords()\n",
    "        self.max_keywords = config.get_max_keywords()\n",
    "        self.min_keywords = config.get_min_keywords()\n",
    "        self.junction_keywords = config.get_junction_keywords()\n",
    "        self.disjunction_keywords = config.get_disjunction_keywords()\n",
    "        self.greater_keywords = config.get_greater_keywords()\n",
    "        self.less_keywords = config.get_less_keywords()\n",
    "        self.between_keywords = config.get_between_keywords()\n",
    "        self.order_by_keywords = config.get_order_by_keywords()\n",
    "        self.group_by_keywords = config.get_group_by_keywords()\n",
    "        self.negation_keywords = config.get_negation_keywords()\n",
    "\n",
    "    def set_thesaurus(self, thesaurus):\n",
    "        self.thesaurus_object = thesaurus\n",
    "\n",
    "    def remove_accents(self, string):\n",
    "        nkfd_form = unicodedata.normalize('NFKD', str(string))\n",
    "        return u\"\".join([c for c in nkfd_form if not unicodedata.combining(c)])\n",
    "\n",
    "    def parse_sentence(self, sentence):\n",
    "        number_of_table = 0\n",
    "        number_of_select_column = 0\n",
    "        number_of_where_column = 0\n",
    "        last_table_position = 0\n",
    "        columns_of_select = []\n",
    "        columns_of_where = []\n",
    "        \n",
    "        # ---------------------------------------------------------------------\n",
    "\n",
    "        input_for_finding_value=sentence\n",
    "        columns_of_values_of_where=[]\n",
    "\n",
    "        filter_list=[\",\",\"!\"]\n",
    "\n",
    "        for filter_element in filter_list:\n",
    "            input_for_finding_value=input_for_finding_value.replace(filter_element,\" \")\n",
    "\n",
    "        input_word_list=input_for_finding_value.split()\n",
    "        \n",
    "        # print \"asd -> \",input_word_list    \n",
    "\n",
    "\n",
    "        #===    clause extractor\n",
    "\n",
    "\n",
    "        number_of_where_column_temp = 0\n",
    "        number_of_table_temp = 0\n",
    "        last_table_position_temp = 0\n",
    "        start_phrase = ''\n",
    "        med_phrase = ''\n",
    "        end_phrase = ''\n",
    "\n",
    "        for i in range(0, len(input_word_list)):            \n",
    "            if input_word_list[i] in self.database_dico:\n",
    "                if number_of_table_temp == 0:\n",
    "                    start_phrase = input_word_list[:i]\n",
    "                number_of_table_temp+=1\n",
    "                last_table_position_temp = i\n",
    "            for table in self.database_dico:\n",
    "                if input_word_list[i] in self.database_dico[table]:\n",
    "                    if number_of_where_column_temp == 0:\n",
    "                        med_phrase = input_word_list[len(start_phrase):last_table_position_temp+1]\n",
    "                    number_of_where_column_temp+=1\n",
    "                    break\n",
    "                else:\n",
    "                    if (number_of_table_temp != 0) and (number_of_where_column_temp == 0) and (i == (len(input_word_list)-1)):\n",
    "                        med_phrase = input_word_list[len(start_phrase):]\n",
    "\n",
    "        end_phrase = input_word_list[len(start_phrase) + len(med_phrase):]\n",
    "        irext = ' '.join(end_phrase)\n",
    "        # print 'irext :',irext\n",
    "\n",
    "\n",
    "        #===       \n",
    "\n",
    "        # condition_str_where='where'\n",
    "        # exist_check_where=sentence.find(condition_str_where)\n",
    "\n",
    "        # condition_str_for='for'\n",
    "        # exist_check_for=sentence.find(condition_str_for)\n",
    "        # if exist_check_where != -1 or exist_check_for != -1:\n",
    "\n",
    "        if irext :\n",
    "\n",
    "            # print \"entered\"\n",
    "\n",
    "            # if  exist_check_where != -1 :   \n",
    "            #     irext=sentence.split(condition_str_where)[1]   \n",
    "            # else :\n",
    "            #     irext=sentence.split(condition_str_for)[1]     \n",
    "\n",
    "            mirext=irext.lower()\n",
    "           \n",
    "            # print \"-----\"\n",
    "            # print \"sentence : \",sentence\n",
    "            # print \"irext : \",irext            \n",
    "            # print \"-----\"\n",
    "\n",
    "            filter_list=[\",\",\"!\"]\n",
    "\n",
    "            for filter_element in filter_list:\n",
    "                irext=irext.replace(filter_element,\" \")\n",
    "\n",
    "            assignment_list=[\" equals to \",\" equal to \",\"=\",\" is \",\":\",\" equals \",\" equal \",\" than \"]\n",
    "            maverickjoy_assigner_convention =\"res@3#>>\"\n",
    "            \n",
    "            for assigners in assignment_list :\n",
    "                irext=irext.replace(assigners,\" res@3#>> \")\n",
    "                # print \"ire : \",irext        \n",
    "            # print 'irext:',irext\n",
    "        \n",
    "\n",
    "            # replace all spaces from values to <_> for proper value assignment in SQL\n",
    "            # eg. (where name is 'abc def') -> (where name is abc<_>def)\n",
    "            for i in re.findall(\"('.*?')\",irext):\n",
    "                irext = irext.replace(i,i.replace(' ','<_>').replace(\"'\",''))\n",
    "\n",
    "            irext_list = irext.split()\n",
    "            # print \"ire : \",irext_list\n",
    "\n",
    "            index_list_values=[(i+1) for i,x in enumerate(irext_list) if x == maverickjoy_assigner_convention]\n",
    "            # print \"ilv : \",index_list_values\n",
    "\n",
    "            for index in index_list_values:\n",
    "                if index < len(irext_list):\n",
    "                    # replace back <_> to spaces from the values assigned\n",
    "                    columns_of_values_of_where.append(str(\"'\"+str(irext_list[index]).replace('<_>',' ')+\"'\"))      \n",
    "\n",
    "            # print \" = > \",columns_of_values_of_where   \n",
    "\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        \n",
    "        tables_of_from = []\n",
    "        select_phrase = ''\n",
    "        from_phrase = ''\n",
    "        where_phrase = ''\n",
    "        \n",
    "        words = re.findall(r\"[\\w]+\", self.remove_accents(sentence))\n",
    "\n",
    "        for i in range(0, len(words)):            \n",
    "            if words[i] in self.database_dico:\n",
    "                if number_of_table == 0:\n",
    "                    select_phrase = words[:i]\n",
    "                tables_of_from.append(words[i])\n",
    "                number_of_table+=1\n",
    "                last_table_position = i\n",
    "            for table in self.database_dico:\n",
    "                if words[i] in self.database_dico[table]:\n",
    "                    if number_of_table == 0:\n",
    "                        columns_of_select.append(words[i])\n",
    "                        number_of_select_column+=1\n",
    "                    else:\n",
    "                        if number_of_where_column == 0:\n",
    "                            from_phrase = words[len(select_phrase):last_table_position+1]\n",
    "                        columns_of_where.append(words[i])\n",
    "                        number_of_where_column+=1\n",
    "                    break\n",
    "                else:\n",
    "                    if (number_of_table != 0) and (number_of_where_column == 0) and (i == (len(words)-1)):\n",
    "                        from_phrase = words[len(select_phrase):]\n",
    "\n",
    "        where_phrase = words[len(select_phrase) + len(from_phrase):]\n",
    "\n",
    "        # print \"where => \", where_phrase\n",
    "        \n",
    "        if (number_of_select_column + number_of_table + number_of_where_column) == 0:\n",
    "            raise ParsingException(\"No keyword found in sentence!\")\n",
    "\n",
    "        if len(tables_of_from) > 0:\n",
    "            from_phrases = []\n",
    "            previous_index = 0\n",
    "            for i in range(0,len(from_phrase)):\n",
    "                if from_phrase[i] in tables_of_from:\n",
    "                    from_phrases.append(from_phrase[previous_index:i+1])\n",
    "                    previous_index = i+1\n",
    "\n",
    "            last_junction_word_index = -1\n",
    "\n",
    "            for i in range(0, len(from_phrases)):\n",
    "                number_of_junction_words = 0\n",
    "                number_of_disjunction_words = 0\n",
    "\n",
    "                for word in from_phrases[i]:\n",
    "                    if word in self.junction_keywords:\n",
    "                        number_of_junction_words += 1\n",
    "                    if word in self.disjunction_keywords:\n",
    "                        number_of_disjunction_words += 1\n",
    "\n",
    "                if (number_of_junction_words + number_of_disjunction_words) > 0:\n",
    "                    last_junction_word_index = i\n",
    "\n",
    "            if last_junction_word_index == -1:\n",
    "                from_phrase = sum(from_phrases[:1], [])\n",
    "                where_phrase = sum(from_phrases[1:], []) + where_phrase\n",
    "            else:\n",
    "                 from_phrase = sum(from_phrases[:last_junction_word_index+1], [])\n",
    "                 where_phrase = sum(from_phrases[last_junction_word_index+1:], []) + where_phrase\n",
    "\n",
    "        real_tables_of_from = []\n",
    "\n",
    "        for word in from_phrase:\n",
    "            if word in tables_of_from:\n",
    "                real_tables_of_from.append(word)\n",
    "        tables_of_from = real_tables_of_from\n",
    "\n",
    "        if len(tables_of_from) == 0:\n",
    "            raise ParsingException(\"No table name found in sentence!\")\n",
    "\n",
    "        group_by_phrase = []\n",
    "        order_by_phrase = []\n",
    "        new_where_phrase = []\n",
    "        previous_index = 0\n",
    "        previous_phrase_type = 0\n",
    "        yet_where = 0\n",
    "\n",
    "        for i in range(0, len(where_phrase)):\n",
    "            if where_phrase[i] in self.order_by_keywords:\n",
    "                if yet_where > 0:\n",
    "                    if previous_phrase_type == 1:\n",
    "                        order_by_phrase.append(where_phrase[previous_index:i])\n",
    "                    elif previous_phrase_type == 2:\n",
    "                        group_by_phrase.append(where_phrase[previous_index:i])\n",
    "                else:\n",
    "                    new_where_phrase.append(where_phrase[previous_index:i])\n",
    "                previous_index = i\n",
    "                previous_phrase_type = 1\n",
    "                yet_where += 1\n",
    "            if where_phrase[i] in self.group_by_keywords:\n",
    "                if yet_where > 0:\n",
    "                    if previous_phrase_type == 1:\n",
    "                        order_by_phrase.append(where_phrase[previous_index:i])\n",
    "                    elif previous_phrase_type == 2:\n",
    "                        group_by_phrase.append(where_phrase[previous_index:i])\n",
    "                else:\n",
    "                    new_where_phrase.append(where_phrase[previous_index:i])\n",
    "                previous_index = i\n",
    "                previous_phrase_type = 2\n",
    "                yet_where += 1\n",
    "\n",
    "        if previous_phrase_type == 1:\n",
    "            order_by_phrase.append(where_phrase[previous_index:])\n",
    "        elif previous_phrase_type == 2:\n",
    "            group_by_phrase.append(where_phrase[previous_index:])\n",
    "        else:\n",
    "            new_where_phrase.append(where_phrase)\n",
    "        \n",
    "        select_parser = SelectParser(columns_of_select, tables_of_from, select_phrase, self.count_keywords, self.sum_keywords, self.average_keywords, self.max_keywords, self.min_keywords, self.database_dico)\n",
    "        from_parser = FromParser(tables_of_from, columns_of_select, columns_of_where, self.database_object)\n",
    "        where_parser = WhereParser(new_where_phrase, tables_of_from, self.count_keywords, self.sum_keywords, self.average_keywords, self.max_keywords, self.min_keywords, self.greater_keywords, self.less_keywords, self.between_keywords, self.negation_keywords, self.junction_keywords, self.disjunction_keywords, self.database_dico, columns_of_values_of_where)\n",
    "        group_by_parser = GroupByParser(group_by_phrase, tables_of_from, self.database_dico)\n",
    "        order_by_parser = OrderByParser(order_by_phrase, tables_of_from, self.database_dico)\n",
    "\n",
    "        select_parser.start()\n",
    "        from_parser.start()\n",
    "        where_parser.start()\n",
    "        group_by_parser.start()\n",
    "        order_by_parser.start()\n",
    "\n",
    "        queries = from_parser.join()\n",
    "\n",
    "\n",
    "\n",
    "        if queries is None:\n",
    "            raise ParsingException(\"There is at least one unattainable column from the table of FROM!\")\n",
    "\n",
    "        select_objects = select_parser.join()\n",
    "        where_objects = where_parser.join()\n",
    "        group_by_objects = group_by_parser.join()\n",
    "        order_by_objects = order_by_parser.join()\n",
    "\n",
    "        for i in range(0, len(queries)):\n",
    "            query = queries[i]\n",
    "            query.set_select(select_objects[i])\n",
    "            query.set_where(where_objects[i])\n",
    "            query.set_group_by(group_by_objects[i])\n",
    "            query.set_order_by(order_by_objects[i])\n",
    "\n",
    "        return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*\n",
    "\n",
    "import os, sys, getopt\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "\n",
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'\n",
    "\n",
    "class ln2sql:\n",
    "    def __init__(self, database_path, input_sentence, language_path, thesaurus_path, json_output_path):\n",
    "        database = Database()\n",
    "        database.load(database_path)\n",
    "        #database.print_me()\n",
    "\n",
    "        config = LangConfig()\n",
    "        config.load(language_path)\n",
    "\n",
    "        parser = Parser(database, config)\n",
    "\n",
    "        if thesaurus_path is not None:\n",
    "            thesaurus = Thesaurus()\n",
    "            thesaurus.load(thesaurus_path)\n",
    "            parser.set_thesaurus(thesaurus)\n",
    "\n",
    "        queries = parser.parse_sentence(input_sentence)\n",
    "\n",
    "        if json_output_path is not None:\n",
    "            self.remove_json(json_output_path)\n",
    "            for query in queries:\n",
    "                query.print_json(json_output_path)\n",
    "\n",
    "        if(len(queries) > 1):\n",
    "            if settings.DEBUG :\n",
    "                print('--------- queries is more than one')\n",
    "            self.query = None\n",
    "\n",
    "            raise Exception('More than one query')\n",
    "        else :\n",
    "            self.query = queries[0]\n",
    "\n",
    "        if settings.DEBUG :\n",
    "            for query in queries:\n",
    "                print (query)\n",
    "\n",
    "    def getQuery(self):\n",
    "        return self.query\n",
    "\n",
    "    def remove_json(self, filename=\"output.json\"):\n",
    "        if os.path.exists(filename):\n",
    "            os.remove(filename)\n",
    "\n",
    "def print_help_message():\n",
    "    if settings.DEBUG :\n",
    "        print ('\\n')\n",
    "        print ('Usage:')\n",
    "        print ('\\tpython ln2sql.py -d <path> -l <path> -i <input-sentence> [-t <path>] [-j <path>]')\n",
    "        print ('Parameters:')\n",
    "        print ('\\t-h\\t\\t\\tprint this help message')\n",
    "        print ('\\t-d <path>\\t\\tpath to SQL dump file')\n",
    "        print ('\\t-l <path>\\t\\tpath to language configuration file')\n",
    "        print ('\\t-i <input-sentence>\\tinput sentence to parse')\n",
    "        print ('\\t-j <path>\\t\\tpath to JSON output file')\n",
    "        print ('\\t-t <path>\\t\\tpath to thesaurus file')\n",
    "        print ('\\n')\n",
    "\n",
    "def main(argv):\n",
    "    # try:\n",
    "    opts, args = getopt.getopt(argv,\"d:l:i:t:j:\")\n",
    "    database_path = None\n",
    "    input_sentence = None\n",
    "    language_path = None\n",
    "    thesaurus_path = None\n",
    "    json_output_path = None\n",
    "\n",
    "    for i in range(0, len(opts)):\n",
    "        if opts[i][0] == \"-d\":\n",
    "            database_path = opts[i][1]\n",
    "        elif opts[i][0] == \"-l\":\n",
    "            language_path = opts[i][1]\n",
    "        elif opts[i][0] == \"-i\":\n",
    "            input_sentence = opts[i][1]\n",
    "        elif opts[i][0] == \"-j\":\n",
    "            json_output_path = opts[i][1]\n",
    "        elif opts[i][0] == \"-t\":\n",
    "            thesaurus_path = opts[i][1]\n",
    "        else:\n",
    "            print_help_message()\n",
    "            # sys.exit()\n",
    "            raise getopt.GetoptError('ln2sqlmodule : Invalid args received',None)\n",
    "    \n",
    "    if (database_path is None) or (input_sentence is None) or (language_path is None):\n",
    "        raise getopt.GetoptError('ln2sqlmodule : Invalid args received',None)\n",
    "    else:\n",
    "        if thesaurus_path is not None:\n",
    "            thesaurus_path = str(thesaurus_path)\n",
    "        if json_output_path is not None:\n",
    "            json_output_path = str(json_output_path)\n",
    "\n",
    "    #try:\n",
    "    ln2sqlObj = ln2sql(str(database_path), str(input_sentence), str(language_path), thesaurus_path, json_output_path)\n",
    "    \n",
    "    return ln2sqlObj.getQuery()\n",
    "    #except Exception, e:\n",
    "    #    print color.BOLD + color.RED + str(e) + color.END\n",
    "\n",
    "    # except getopt.GetoptError:\n",
    "    #     print_help_message()\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E\n",
      "======================================================================\n",
      "ERROR: C:\\Users\\Ishita_J\\AppData\\Roaming\\jupyter\\runtime\\kernel-772c020b-3fd3-4832-a8e6-29e34268b580 (unittest.loader._FailedTest)\n",
      "----------------------------------------------------------------------\n",
      "AttributeError: module '__main__' has no attribute 'C:\\Users\\Ishita_J\\AppData\\Roaming\\jupyter\\runtime\\kernel-772c020b-3fd3-4832-a8e6-29e34268b580'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ishita_J\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3304: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "#import __init__ as ln2sqlmodule\n",
    "\n",
    "\n",
    "class Testln2sql(unittest.TestCase):\n",
    "\n",
    "    def test_getSql(self):\n",
    "        tests = [\n",
    "            {\n",
    "                \"input\": \"emp\",\n",
    "                \"output\": \"SELECT * FROM emp;\"\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"name of all emp\",\n",
    "                \"output\": \"SELECT emp.name FROM emp;\"\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"name and score for emp with id = 2\",\n",
    "                \"output\": \"SELECT emp.name, emp.score FROM emp WHERE emp.id = '2';\"\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"all data for city where cityName = 'pune'\",\n",
    "                \"output\": \"SELECT * FROM city WHERE city.cityName = 'pune';\"  \n",
    "            },\n",
    "            {\n",
    "                \"input\": \"cityName for emp\",\n",
    "                \"output\": \"SELECT city.cityName FROM emp INNER JOIN city ON emp.cityId = city.id;\"\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"cityName for emp with id = 2\",\n",
    "                \"output\": \"SELECT city.cityName FROM emp INNER JOIN city ON emp.cityId = city.id WHERE emp.id = '2';\"\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"cityName and score for emp with id = 2\",\n",
    "                \"output\": \"SELECT city.cityName, emp.score FROM emp INNER JOIN city ON emp.cityId = city.id WHERE emp.id = '2';\"\n",
    "            },\n",
    "\n",
    "        ]\n",
    "\n",
    "        for test in tests:\n",
    "            self.assertEqual(\n",
    "                str(ln2sqlmodule.getSql(test['input'],'emp.sql')), test['output'])\n",
    "\n",
    "    def test_getSql_like(self):\n",
    "        tests = [\n",
    "            {\n",
    "                \"input\": \"emp\",\n",
    "                \"output\": \"SELECT * FROM emp;\"\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"name of all emp\",\n",
    "                \"output\": \"SELECT emp.name FROM emp;\"\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"name and score for emp with name = rupinder\",\n",
    "                \"output\": \"SELECT emp.name, emp.score FROM emp WHERE emp.name LIKE '%rupinder%';\"\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"all data for city where cityName is 'pune'\",\n",
    "                \"output\": \"SELECT * FROM city WHERE city.cityName LIKE '%pune%';\"  \n",
    "            },\n",
    "            {\n",
    "                \"input\": \"cityName for emp\",\n",
    "                \"output\": \"SELECT city.cityName FROM emp INNER JOIN city ON emp.cityId = city.id;\"\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"cityName for emp with name is 'rupinder singh'\",\n",
    "                \"output\": \"SELECT city.cityName FROM emp INNER JOIN city ON emp.cityId = city.id WHERE emp.name LIKE '%rupinder%singh%';\"\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"cityName and score for emp with score = 2\",\n",
    "                \"output\": \"SELECT city.cityName, emp.score FROM emp INNER JOIN city ON emp.cityId = city.id WHERE emp.score LIKE '%2%';\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        for test in tests:\n",
    "            self.assertEqual(\n",
    "                str(ln2sqlmodule.getSql_like(test['input'],'emp.sql')), test['output'])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectGenerator(Thread):\n",
    "    def __init__(self):\n",
    "        Thread.__init__(self)\n",
    "\n",
    "    def run(self):\n",
    "        return\n",
    "\n",
    "    def join(self):\n",
    "        Thread.join(self)\n",
    "        return\n",
    "\n",
    "class FromGenerator(Thread):\n",
    "    def __init__(self):\n",
    "        Thread.__init__(self)\n",
    "\n",
    "    def run(self):\n",
    "        return\n",
    "\n",
    "    def join(self):\n",
    "        Thread.join(self)\n",
    "        return self.queries\n",
    "\n",
    "class WhereGenerator(Thread):\n",
    "    def __init__(self):\n",
    "        Thread.__init__(self)\n",
    "\n",
    "    def run(self):\n",
    "        return\n",
    "\n",
    "    def join(self):\n",
    "        Thread.join(self)\n",
    "        return\n",
    "\n",
    "class JoinGenerator(Thread):\n",
    "    def __init__(self):\n",
    "        Thread.__init__(self)\n",
    "\n",
    "    def run(self):\n",
    "        return\n",
    "\n",
    "    def join(self):\n",
    "        Thread.join(self)\n",
    "        return\n",
    "\n",
    "class GroupByGenerator(Thread):\n",
    "    def __init__(self):\n",
    "        Thread.__init__(self)\n",
    "\n",
    "    def run(self):\n",
    "        return\n",
    "\n",
    "    def join(self):\n",
    "        Thread.join(self)\n",
    "        return\n",
    "\n",
    "class OrderByGenerator(Thread):\n",
    "    def __init__(self):\n",
    "        Thread.__init__(self)\n",
    "\n",
    "    def run(self):\n",
    "        return\n",
    "\n",
    "    def join(self):\n",
    "        Thread.join(self)\n",
    "        return\n",
    "\n",
    "class Generator:\n",
    "\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def generate(self, queries):\n",
    "        for query in queries:\n",
    "            select_object = query.get_select()\n",
    "            from_object = query.get_from()\n",
    "            where_object = query.get_where()\n",
    "            join_object = query.get_join()\n",
    "            group_by_object = query.get_group_by()\n",
    "            order_by_object = query.get_order_by()\n",
    "\n",
    "            select_generator = SelectGenerator(select_object)\n",
    "            from_generator = FromGenerator(from_object)\n",
    "            where_generator = WhereGenerator(where_object)\n",
    "            join_generator = JoinGenerator(join_object)\n",
    "            group_by_generator = GroupByGenerator(group_by_object)\n",
    "            order_by_generator = OrderByGenerator(order_by_object)\n",
    "\n",
    "            select_generator.start()\n",
    "            from_generator.start()\n",
    "            where_generator.start()\n",
    "            join_generator.start()\n",
    "            group_by_generator.start()\n",
    "            order_by_generator.start()\n",
    "\n",
    "            select_phrase = select_generator.join()\n",
    "            from_phrase = from_generator.join()\n",
    "            where_phrase = where_generator.join()\n",
    "            join_phrase = join_generator.join()\n",
    "            group_by_phrase = group_by_generator.join()\n",
    "            order_by_phrase = order_by_generator.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSql(query, sqlDump, outputFile=None):\n",
    "    # unit test\n",
    "    # args = ['-d', 'ln2sqlmodule/emp_dump.sql', '-l', 'ln2sqlmodule/lang/english.csv', '-i', query, '-j', 'ln2sqlmodule/output.json','-x']\n",
    "    # args = ['-d', 'ln2sqlmodule/emp_dump.sql', 'ln2sqlmodule/lang/english.csv', '-i', query, '-j', 'ln2sqlmodule/output.json']\n",
    "\n",
    "    # args = ['-d', 'ln2sqlmodule/timesheet.sql', '-l',\n",
    "    #         'ln2sqlmodule/lang/english.csv', '-i', query, '-j', 'ln2sqlmodule/output.json']\n",
    "\n",
    "        args = ['-d', sqlDump,\n",
    "                '-l', \"C:/Users/Ishita_J/AppData/Local/Continuum/anaconda3/Lib/site-packages/ln2sqlmodule/lang/english.csv\",\n",
    "                '-i', query,\n",
    "                '-j', outputFile]\n",
    "\n",
    "        sql = main(args)\n",
    "\n",
    "        return str(sql)\n",
    "\n",
    "\n",
    "def getSql_like(query, sqlDump, outputFile=None):\n",
    "        sql = getSql(query, sqlDump, outputFile)\n",
    "\n",
    "        sql = re.sub(\"(WHERE \\S+ )=\", r'\\g<1>LIKE', sql)\n",
    "        sql = re.sub(\"(AND \\S+ )=\", r'\\g<1>LIKE', sql)\n",
    "        sql = re.sub(\"(OR \\S+ )=\", r'\\g<1>LIKE', sql)\n",
    "\n",
    "        # 'abc def' -> '%abc%def%'\n",
    "        for i in re.findall(\"'(.*?)'\", sql):\n",
    "            sql = sql.replace(i, \"%\" + i + \"%\")\n",
    "            sql = sql.replace(i, i.replace(' ', '%'))\n",
    "\n",
    "        return sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "\n",
    "import sys\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "\n",
    "class ParsingException(Exception):\n",
    "    reason = ''\n",
    "    \n",
    "    def __init__(self, reason):\n",
    "        self.reason = reason\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'ParsingException : ' + self.reason\n",
    "\n",
    "class GeneratingException(Exception):\n",
    "    reason = ''\n",
    "\n",
    "    def __init__(self, reason):\n",
    "        self.reason = reason\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'GeneratingException : ' + self.reason\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = getSql(\"get count of all emp\",\"C:/Users/Ishita_J/Desktop/emp.sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x1b[1mSELECT \\x1b[0m\\x1b[1mCOUNT(\\x1b[0m*\\x1b[1m)\\x1b[0m \\x1b[1mFROM \\x1b[0memp;'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSql_like(\"get count of all emp\",\"C:/Users/Ishita_J/Desktop/emp.sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(*) FROM emp;\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "print (re.sub('\\x1b.*?m', '', s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT emp.name FROM emp;\n"
     ]
    }
   ],
   "source": [
    "s = getSql(\"get name of all emp\",\"C:/Users/Ishita_J/Desktop/emp.sql\")\n",
    "print (re.sub('\\x1b.*?m', '', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT emp.name FROM emp WHERE emp.score = '10';\n"
     ]
    }
   ],
   "source": [
    "s = getSql(\"get name of all emp where score = 10 \",\"C:/Users/Ishita_J/Desktop/emp.sql\")\n",
    "print (re.sub('\\x1b.*?m', '', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT emp.name FROM emp WHERE emp.score = '10';\n"
     ]
    }
   ],
   "source": [
    "s = getSql(\"what is the name in emp whose score is 10 \",\"C:/Users/Ishita_J/Desktop/emp.sql\")\n",
    "print (re.sub('\\x1b.*?m', '', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT emp.name FROM emp WHERE emp.score = '10' AND emp.cityId = 'pune';\n"
     ]
    }
   ],
   "source": [
    "s = getSql(\"what is the name in emp whose score is 10 and cityId is pune \",\"C:/Users/Ishita_J/Desktop/emp.sql\")\n",
    "print (re.sub('\\x1b.*?m', '', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(*) FROM emp WHERE emp.cityId = OOV;\n"
     ]
    }
   ],
   "source": [
    "s = getSql(\"what is the number of emp with cityId pune \",\"C:/Users/Ishita_J/Desktop/emp.sql\")\n",
    "print (re.sub('\\x1b.*?m', '', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT MAX(emp.id) FROM emp;\n"
     ]
    }
   ],
   "source": [
    "s = getSql(\"what is the maximum id in emp \",\"C:/Users/Ishita_J/Desktop/emp.sql\")\n",
    "print (re.sub('\\x1b.*?m', '', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT emp.name FROM emp WHERE emp.id = OOV AND MAX(emp.id) = OOV;\n"
     ]
    }
   ],
   "source": [
    "s = getSql(\"what is the name of emp where id = maximum of emp id \",\"C:/Users/Ishita_J/Desktop/emp.sql\")\n",
    "print (re.sub('\\x1b.*?m', '', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
